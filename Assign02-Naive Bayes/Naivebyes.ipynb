{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6nWx45A7BVq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveBayes:\n",
        "    def fit(self, X, y):\n",
        "        pass\n",
        " \n",
        "    def predict(self, X):\n",
        "        pass\n",
        "\n",
        "    def get_class_probability(self, x):\n",
        "        pass\n",
        "\n",
        "    def gaussian_density(self, x, mean, var):\n",
        "        pass"
      ],
      "metadata": {
        "id": "AL45Wen77aSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveBayes:\n",
        "    def fit(self, X, y):\n",
        "        # ...\n",
        "\n",
        "        for c in range(self.n_classes):\n",
        "            # create a subset of data for the specific class 'c'\n",
        "            X_c = X[y == c]\n",
        "            \n",
        "            # calculate statistics and update zero-matrices, rows=classes, cols=features\n",
        "            self.mean[c, :] = np.mean(X_c, axis=0)\n",
        "            self.variance[c, :] = np.var(X_c, axis=0)\n",
        "            self.priors[c] = X_c.shape[0] / self.n_samples"
      ],
      "metadata": {
        "id": "jSJ9Doib7bNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveBayes:\n",
        "    #...\n",
        "    def gaussian_density(self, x, mean, var):\n",
        "        # implementation of gaussian density function\n",
        "        const = 1 / np.sqrt(var * 2 * np.pi)\n",
        "        proba = np.exp(-0.5 * ((x - mean) ** 2 / var))\n",
        "    return const * proba"
      ],
      "metadata": {
        "id": "wV7Q-yC47f_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveBayes:\n",
        "    #...\n",
        "    def get_class_probability(self, x):\n",
        "        # store new posteriors for each class in a single list\n",
        "        posteriors = list()\n",
        "\n",
        "        for c in range(self.n_classes):\n",
        "            # get summary stats & prior\n",
        "            mean = self.mean[c]\n",
        "            variance = self.variance[c]\n",
        "            prior = np.log(self.priors[c])\n",
        "            \n",
        "            # calculate new posterior & append to list\n",
        "            posterior = np.sum(np.log(self.gaussian_density(x, mean, variance)))\n",
        "            posterior = prior + posterior\n",
        "            posteriors.append(posterior)\n",
        "        \n",
        "        # return the index with the highest class probability\n",
        "        return np.argmax(posteriors)"
      ],
      "metadata": {
        "id": "eUHHxYcZ7lEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveBayes:\n",
        "        #...\n",
        "    def predict(self, X):\n",
        "        # for each sample x in the dataset X\n",
        "        y_hat = [self.get_class_probability(x) for x in X]\n",
        "        return np.array(y_hat)"
      ],
      "metadata": {
        "id": "P6S1RVkN7qqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# load iris dataset\n",
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/test.csv')\n",
        "\n",
        "# normalizing data\n",
        "train_norm=(train-train.min())/(train.max()-train.min())\n",
        "\n",
        "X = test.data\n",
        "y = test.target\n",
        "\n",
        "# split into train and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "# instantiate, train and predict Naive Bayes Classifier\n",
        "nb = NaiveBayes()\n",
        "nb.fit(X_train, y_train)\n",
        "predictions = nb.predict(X_test)\n",
        "\n",
        "# helper function to calculate accuracy\n",
        "def get_accuracy(y_true, y_hat):\n",
        "    return np.sum(y_true==y_hat) / len(y_true)\n",
        "  \n",
        "# print results\n",
        "print('Naive Bayes Accuracy: ', get_accuracy(y_test, predictions))"
      ],
      "metadata": {
        "id": "lSg7QuQ37uw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id = test_data[\"Id\"]\n",
        "Test = pd.DataFrame(id)\n",
        "arr=[]\n",
        "for row in id:\n",
        "  arr.append(L[row])\n",
        "Test[\"Cover type\"] = arr\n",
        "Test.to_csv('read.csv',index = False)"
      ],
      "metadata": {
        "id": "KQoEquTD9RvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0TfjMhQh7zzw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}